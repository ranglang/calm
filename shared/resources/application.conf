include "local.conf"

request-idle = 1 seconds

env = "development"
env = ${?ENV}

akka.log-dead-letters=10

akka {
  persistence {
    journal-plugin-fallback {
      recovery-event-timeout = 60s

      circuit-breaker {
        max-failures = 20
        call-timeout = 28s
        reset-timeout = 60s
      }
    }
  }
}


akka.test.default-timeout = 10.seconds
memcachedcache =${?MEMCACHED}

scheduleEnable="1"
scheduleEnable =${?SCHEDULE_ENABLE}

tempEnabled = "0"
tempEnabled = ${?TEMP_ENABLED}

blocking-io-dispatcher {
  type = Dispatcher
  executor = "thread-pool-executor"
  thread-pool-executor {
    fixed-pool-size = 32
  }
  throughput = 1
}


akka {
  loggers = ["akka.event.slf4j.Slf4jLogger"]
  log-dead-letters=10
}

cache {
  memcached = ${?MEMCACHED}
}

ctx.default {
  host = ${?PG_HOST}
  port = ${?PG_PORT}
  user = ${?PG_USERNAME}
  password = ${?PG_PASSWORD}
  database =  ${?PG_DATABASE}
  poolMaxQueueSize = 4
  poolMaxObjects = 4
  poolMaxIdle = 999999999
  poolValidationInterval = 10000
}


ctx {
  host = ${?PG_HOST}
  port = ${?PG_PORT}
  user = ${?PG_USERNAME}
  password = ${?PG_PASSWORD}
  database =  ${?PG_DATABASE}
  poolMaxQueueSize = 4
  poolMaxObjects = 4
  poolMaxIdle = 999999999
  poolValidationInterval = 10000
}


email.host = ${?EMAIL_HOST}
email.port = 465
email.port = ${?EMAIL_PORT}
email.user_name  = ${?EMAIL_USER_NAME}
email.password  = ${?EMAIL_PASSWORD}

trade.user_name  =""
trade.ak  = ""
trade.user_name  = ${?TRADE_USERNAME}
trade.ak  = ${?TRADE_AK}

akka.http.server.request-timeout = 60.seconds

lqiong {
  idle = 0 seconds
  save-limit = 40 minutes
  stock = {
    timeout = 300.seconds
  }
}



akka.loglevel = "INFO"

akka {
  http.server.default-host-header = "localhost"
  loggers = ["akka.event.slf4j.Slf4jLogger"]
  logging-filter = "akka.event.slf4j.Slf4jLoggingFilter"

  actor {
    provider = "cluster"
  }

}

#management-config
akka.management {
  cluster.bootstrap {
    contact-point-discovery {
      # pick the discovery method you'd like to use:
      discovery-method = kubernetes-api
      required-contact-point-nr = 1
      required-contact-point-nr = ${?REQUIRED_CONTACT_POINT_NR}
    }
  }
}

akka.actor.allow-java-serialization = true

#management-config

akka.management {
  health-checks {
    readiness-checks {
      example-ready = "akka.sample.cluster.kubernetes.DemoHealthCheckCustom1"
    }
  }
}


akka.cluster.sharding.passivation {
  strategy = default-strategy
  default-strategy {
    idle-entity.timeout = 30.days
  }
}

akka.cluster.sharding.remember-entities = on
akka.cluster.min-nr-of-members = 2

akka.cluster.sharding {
  # Number of shards used by the default HashCodeMessageExtractor
  # when no other message extractor is defined. This value must be
  # the same for all nodes in the cluster and that is verified by
  # configuration check when joining. Changing the value requires
  # stopping all nodes in the cluster.
  number-of-shards = 2
}

akka.cluster.sharding.healthcheck.names = ["counter-1"]

akka.remote.artery.canonical.port = 25521



akka {
  actor {
    serializers {
      jackson-json = "akka.serialization.jackson.JacksonJsonSerializer"
      jackson-cbor = "akka.serialization.jackson.JacksonCborSerializer"
      proto = "akka.remote.serialization.ProtobufSerializer"
    }

    serialization-bindings {
      "com.lqiong.claim.actor.StockPState" =  jackson-json
      "com.lqiong.claim.actor.PStockEvent" =  jackson-json
      "com.lqiong.claim.actor.PStockCommand" =  jackson-json
      "com.lqiong.jep.Encodable" = jackson-cbor
      "com.google.protobuf.Message" = proto
    }
  }
}




// general.conf is included only for shared settings used for the akka-persistence-jdbc tests
include "general.conf"


jdbc-journal {
  slick = ${slick}
}

# the akka-persistence-snapshot-store in use
jdbc-snapshot-store {
  slick = ${slick}
}

# the akka-persistence-query provider in use
jdbc-read-journal {
  slick = ${slick}
}

# the akka-persistence-jdbc provider in use for durable state store
jdbc-durable-state-store {
  slick = ${slick}
}


slick {
  profile = "slick.jdbc.PostgresProfile$"
  db {
    host = ${?PG_HOST}
    url = "jdbc:postgresql://"${PG_HOST}":"${PG_PORT}"/"${PG_DATABASE}"?reWriteBatchedInserts=true"
    user = ${?PG_USERNAME}
    password = ${?PG_PASSWORD}
    driver = "org.postgresql.Driver"
    numThreads = 5
    maxConnections = 5
    minConnections = 1
  }
}

akka.persistence.journal.plugin = "akka.persistence.r2dbc.journal"
akka.persistence.snapshot-store.plugin = "akka.persistence.r2dbc.snapshot"
//akka.persistence.state.plugin = "akka.persistence.r2dbc.durable-state-store"
akka.persistence.state.plugin = "akka.persistence.r2dbc.state"

akka.persistence.r2dbc {
  dialect = "postgres"
  connection-factory {
    driver = "postgres"
    host = "localhost"
    host = ${?PG_HOST}
    port = ${?PG_PORT}
    database = "postgres"
    database = ${?PG_DATABASE}
    user = "postgres"
    user = ${?PG_USERNAME}
    password = "postgres"
    password = ${?PG_PASSWORD}

    # ssl {
    #   enabled = on
    #   mode = "VERIFY_CA"
    #   root-cert = "/path/db_root.crt"
    # }
  }
}


akka.persistence.r2dbc {
  journal {
    class = "akka.persistence.r2dbc.journal.R2dbcJournal"

    # name of the table to use for events
    table = "event_journal1"

    # event replay is using akka.persistence.r2dbc.query.buffer-size

  }
}

// #snapshot-settings

// #durable-state-settings

akka.persistence.r2dbc {
  snapshot {
    class = "akka.persistence.r2dbc.snapshot.R2dbcSnapshotStore"
    table = "snapshot1"
  }
}

// #durable-state-settings
akka.persistence.r2dbc {
  # Durable state store
  state {
    class = "akka.persistence.r2dbc.state.R2dbcDurableStateStoreProvider"

    table = "durable_state1"

    # When this is enabled the updates verifies that the revision is +1 of
    # previous revision. There might be a small performance gain if
    # this is disabled.
    assert-single-writer = on
  }
}


akka.actor.serializers {
  kryo = "com.twitter.chill.akka.AkkaSerializer"
}

akka.actor.serialization-bindings {
  "java.io.Serializable" = kryo
}

akka.actor {
  # Set this to on to enable serialization-bindings defined in
  # additional-serialization-bindings. Those are by default not included
  # for backwards compatibility reasons. They are enabled by default if
  # akka.remote.artery.enabled=on.
  enable-additional-serialization-bindings = on

  allow-java-serialization = off
}


akka.serialization.jackson {

  # The Jackson JSON serializer will register these modules.
#   jackson-modules += "akka.serialization.jackson.AkkaJacksonModule"
#   # AkkaTypedJacksonModule optionally included if akka-actor-typed is in classpath
#   jackson-modules += "akka.serialization.jackson.AkkaTypedJacksonModule"
#   # AkkaStreamsModule optionally included if akka-streams is in classpath
#   jackson-modules += "akka.serialization.jackson.AkkaStreamJacksonModule"
#   jackson-modules += "com.fasterxml.jackson.module.paramnames.ParameterNamesModule"
#   jackson-modules += "com.fasterxml.jackson.datatype.jdk8.Jdk8Module"
#   jackson-modules += "com.fasterxml.jackson.datatype.jsr310.JavaTimeModule"
#   jackson-modules += "com.fasterxml.jackson.module.scala.DefaultScalaModule"
#   jackson-modules += "com.fasterxml.jackson.datatype:jackson-datatype-joda"
  jackson-modules += "com.fasterxml.jackson.datatype.joda.JodaModule"
}

akka.serialization.jackson.allowed-class-prefix = ["com.lqiong.claim"]
